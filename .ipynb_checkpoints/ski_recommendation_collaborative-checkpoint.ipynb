{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avant Ski/ Send It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by: Stephanie Ciaccia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skiing holds a prominent place for those seeking winter recreational activities in the United States. With its stunning mountain ranges and diverse terrain, the country boasts numerous ski resorts that cater to all skill levels, from beginners to seasoned professionals. Skiing offers a unique blend of adventure, physical activity, and natural beauty, making it a popular choice for winter enthusiasts seeking both relaxation and excitement.\n",
    "\n",
    "The ski market in the United States is thriving, contributing significantly to the economy. According to the [National Ski Areas Association (NSAA)](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://nsaa.org/webdocs/Media_Public/IndustryStats/Historical_Skier_Days_1979_2022.pdf), approximately 60.7 million skiers and snowboarders visited 473 ski resorts in the 2021-2022 winter season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skiing is an exhilarating winter activity enjoyed by many, but barriers such as high costs and limited accessibility often hinder people from fully experiencing its joys. Choosing the right ski resort can be overwhelming due to the multitude of options available, and existing websites lack dynamic filtering capabilities based on user preferences.\n",
    "\n",
    "To address these challenges, I'm developing Avant Ski, a ski resort recommendation app. Avant Ski simplifies the ski resort selection process by leveraging data and user preferences. With dynamic filtering features, users can personalize their search based on budget, location, amenities, and skill level. By bridging the gap between ski enthusiasts and their dream destinations, Avant Ski makes skiing accessible to a wider audience, empowering them to plan unforgettable ski trips with confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline, KNNWithZScore,  SVD, SVDpp, NMF, BaselineOnly, CoClustering, SlopeOne, NormalPredictor\n",
    "from surprise.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from IPython.display import Image, display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to print full rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_user_df = pd.read_csv(\"data/cleaned_data_exports/user_df_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = pd.read_csv(\"data/cleaned_data_exports/scraped_feature_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling - Recommendation System\n",
    "The proposed recommendation system will adopt a cascade hybrid approach, integrating user-based filtering and content-based recommendation systems.\n",
    "\n",
    "This **cascade hybrid** approach establishes a hierarchical structure within the recommendation system. The primary model, a collaborative user-based system, will generate the initial set of recommendations based on user preferences and ratings. Then, a secondary model, a content-based system, will refine the recommendations by considering additional factors such as mountain characteristics and user-defined filters. This two-step process aims to provide more accurate and personalized ski resort suggestions.\n",
    "\n",
    "In the **user-based collaborative** filtering phase, the model will analyze the historical ratings of users for different ski resorts. By identifying users with similar rating patterns, the model will predict the target user's ratings for unvisited resorts, leveraging the collective wisdom of similar users.\n",
    "\n",
    "The **content-based system** operates by constructing a matrix of resort features and determining the similarity between resorts based on these features. This approach allows the system to identify resorts with similar characteristics and recommend them based on user preferences.\n",
    "\n",
    "To evaluate the accuracy of the collaborative model, the **Root Mean Square Error (RMSE)** score will be used. This metric quantifies the difference between the actual ratings and the predicted ratings, providing insights into the model's performance in capturing user preferences.\n",
    "\n",
    "While the content-based system does not have an accuracy score, a combination of ski expertise and specific user information will be utilized to subjectively assess the effectiveness of the hybrid model.\n",
    "\n",
    "By utilizing both user-based and content-based approaches, the cascade hybrid recommendation system aims to enhance the ski resort selection process, **offering users more personalized and relevant recommendations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise Data\n",
    "To make this model, we will be using the python package Surprise. This is a scikit tool that uses a range of algorithms made up of matrix factorization-based methods for collaborative filtering. \n",
    "\n",
    "To begin, we will make new dataframe from our final cleaned dataframe with three columns that include user **id, ratings, and movie ids.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_user_df.drop(columns=\"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    1127\n",
       "4.0     936\n",
       "3.0     420\n",
       "2.0     197\n",
       "1.0     115\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_user_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>state</th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>user_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>2010-11-28</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Mt. Bohemia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We happened upon this place about 7 or 8 years...</td>\n",
       "      <td>Peter Mende</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Mt. Bohemia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best in the Midwest \\r\\nI pulled up in the par...</td>\n",
       "      <td>A. cooper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>2011-02-27</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Mt. Bohemia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The scenery and weather is always top notch in...</td>\n",
       "      <td>skylolow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>2012-03-05</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Mt. Bohemia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best place east of the rockies for steeps, tre...</td>\n",
       "      <td>Adye 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>2014-01-28</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Mt. Bohemia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This was my first visit to Bohemia, and I will...</td>\n",
       "      <td>Linda Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Mt. Bohemia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I was also there on the 13 of March. When I lo...</td>\n",
       "      <td>Ryan Craig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     review_date     state   ski_resort  rating  \\\n",
       "1582  2010-11-28  Michigan  Mt. Bohemia     5.0   \n",
       "1613  2010-12-27  Michigan  Mt. Bohemia     5.0   \n",
       "1762  2011-02-27  Michigan  Mt. Bohemia     5.0   \n",
       "1954  2012-03-05  Michigan  Mt. Bohemia     5.0   \n",
       "2137  2014-01-28  Michigan  Mt. Bohemia     5.0   \n",
       "2345  2016-03-16  Michigan  Mt. Bohemia     5.0   \n",
       "\n",
       "                                                 review    user_name  \n",
       "1582  We happened upon this place about 7 or 8 years...  Peter Mende  \n",
       "1613  Best in the Midwest \\r\\nI pulled up in the par...    A. cooper  \n",
       "1762  The scenery and weather is always top notch in...     skylolow  \n",
       "1954  Best place east of the rockies for steeps, tre...       Adye 1  \n",
       "2137  This was my first visit to Bohemia, and I will...  Linda Smith  \n",
       "2345  I was also there on the 13 of March. When I lo...   Ryan Craig  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_user_df.loc[final_user_df['ski_resort'] == \"Mt. Bohemia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying final rewview dataframe\n",
    "surprise_df = final_user_df.copy()\n",
    "\n",
    "#dropping unneeded columns\n",
    "surprise_df = surprise_df[['user_name', 'ski_resort', 'rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Winter Park</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Arapahoe Basin</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Steamboat</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Copper Mountain</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anon_2</td>\n",
       "      <td>Solitude Mountain</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>Payton Sharum</td>\n",
       "      <td>Snowy Range Ski Recreation Area</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>Lori Young</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>Lori Young</td>\n",
       "      <td>Discovery</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>Steven Freund</td>\n",
       "      <td>Solitude Mountain</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>Matt  H</td>\n",
       "      <td>Mt. Baker</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2807 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_name                       ski_resort  rating\n",
       "0            anon_1                      Winter Park     4.0\n",
       "1            anon_1                   Arapahoe Basin     5.0\n",
       "2            anon_1                        Steamboat     5.0\n",
       "3            anon_1                  Copper Mountain     5.0\n",
       "4            anon_2                Solitude Mountain     5.0\n",
       "...             ...                              ...     ...\n",
       "2802  Payton Sharum  Snowy Range Ski Recreation Area     5.0\n",
       "2803     Lori Young                        Discovery     5.0\n",
       "2804     Lori Young                        Discovery     5.0\n",
       "2805  Steven Freund                Solitude Mountain     5.0\n",
       "2806        Matt  H                        Mt. Baker     5.0\n",
       "\n",
       "[2807 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting the number of reviews for each user\n",
    "value_counts = surprise_df['user_name'].value_counts()\n",
    "\n",
    "# selecting only users with more than three reviews\n",
    "selected_users = value_counts[value_counts > 2].index\n",
    "\n",
    "# selecting only the rows where the user_name is in the selected_users list\n",
    "surprise_df = surprise_df[surprise_df['user_name'].isin(selected_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ski Brule              67\n",
       "Killington             49\n",
       "Vail                   49\n",
       "Breckenridge           48\n",
       "Snowbird               35\n",
       "                       ..\n",
       "Bradford                1\n",
       "Mad River Mountain      1\n",
       "New Hermon Mountain     1\n",
       "Black Mountain          1\n",
       "Soda Springs            1\n",
       "Name: ski_resort, Length: 269, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_df['ski_resort'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "#loading final dataset\n",
    "data = Dataset.load_from_df(surprise_df[['user_name', 'ski_resort', 'rating']], reader)\n",
    "\n",
    "#spltting into train and test\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  534 \n",
      "\n",
      "Number of items:  264\n"
     ]
    }
   ],
   "source": [
    "#looking at number of users\n",
    "print('Number of users: ', trainset.n_users, '\\n')\n",
    "print('Number of items: ', trainset.n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Predictor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal Predictor baseline model's Root Mean Squared Error (RMSE) tells us that our predicted rating is **1.41** points away from the actual rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3587\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "baseline = NormalPredictor()\n",
    "\n",
    "#fitting model\n",
    "baseline.fit(trainset)\n",
    "\n",
    "# making prediction on testset\n",
    "predictions = baseline.test(testset)\n",
    "\n",
    "# Save RMSE score\n",
    "baseline_normal = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving normal rmse\n",
    "test_baseline_normal_rmse = 1.358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rmse = [['normal predictor', 1.358, 'n/a']]\n",
    "\n",
    "model_df = pd.DataFrame(data_rmse, columns=['model', 'rmse', 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal predictor</td>\n",
       "      <td>1.358</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model   rmse params\n",
       "0  normal predictor  1.358    n/a"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function to save the RMSE for all model iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_comp(model_name, rmse, params):\n",
    "    model_df.loc[len(model_df.index)] = [model_name, rmse, params] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal Predictor baseline model's Root Mean Squared Error (RMSE) tells us that our predicted rating is **1.41** points away from the actual rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithim Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, I'll be testing all algorithms available in Surprise to deterime which models I should I should further adjust hyperparameters.\n",
    "\n",
    "This code was adapated from this [blog](https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "benchmark = []\n",
    "\n",
    "# Iterate over all algorithms to see which performs beset\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    \n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "benchmark_df = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.966697</td>\n",
       "      <td>0.079655</td>\n",
       "      <td>0.003514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.969806</td>\n",
       "      <td>0.184336</td>\n",
       "      <td>0.009329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>1.000573</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.011771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.046057</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.008980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.157397</td>\n",
       "      <td>0.016383</td>\n",
       "      <td>0.010859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.164445</td>\n",
       "      <td>0.007534</td>\n",
       "      <td>0.009893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.182761</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.002621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>1.192029</td>\n",
       "      <td>0.127330</td>\n",
       "      <td>0.002829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.204152</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.003798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>1.411307</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.003278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "SVD               0.966697  0.079655   0.003514\n",
       "SVDpp             0.969806  0.184336   0.009329\n",
       "BaselineOnly      0.993994  0.001776   0.002175\n",
       "KNNBaseline       1.000573  0.006783   0.011771\n",
       "KNNBasic          1.046057  0.003577   0.008980\n",
       "KNNWithZScore     1.157397  0.016383   0.010859\n",
       "KNNWithMeans      1.164445  0.007534   0.009893\n",
       "CoClustering      1.182761  0.059844   0.002621\n",
       "NMF               1.192029  0.127330   0.002829\n",
       "SlopeOne          1.204152  0.004119   0.003798\n",
       "NormalPredictor   1.411307  0.001365   0.003278"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the intiial test, SVDpp and SVD had the lowerse RMSE scores. I will start adjusting hyperparameters to see which model will perform the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 - SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Singular Value Decomposition (SVD) to reduce the dimensionality of our matrix. SVD is a matrix factorization model that decomposes the reviewer reviews and movies into three matrices. This helps us understand the relationship between users and items, or in this case users and ski resorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.9376  1.0281  0.9532  0.9730  0.0395  \n",
      "Fit time          0.08    0.08    0.08    0.08    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    \n"
     ]
    }
   ],
   "source": [
    "# Cross validate a basic SVD with no hyperparameter tuning expecting sub-par results\n",
    "svd_basic = SVD(random_state=42)\n",
    "\n",
    "results = cross_validate(svd_basic, data, measures=['RMSE'], cv=3, n_jobs = -1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9254\n"
     ]
    }
   ],
   "source": [
    "# Fit to trainset and predict on the testset for evaluation\n",
    "svd_basic.fit(trainset)\n",
    "\n",
    "predictions = svd_basic.test(testset)\n",
    "\n",
    "svd_simple = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd', .925, 'n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 - SVD Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 80, 'n_epochs': 50, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [10, 20, 50, 80, 100],\n",
    "          'n_epochs': [5, 10, 20, 30, 40, 50],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd.fit(data)\n",
    "g_s_svd.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9062\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd = SVD(n_factors=80 ,n_epochs=50, init_mean=0, biased=True)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd.fit(trainset)\n",
    "predictions = g_s_svd.test(testset)\n",
    "g_s_svd_1 = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_grid_1', .92, {'n_factors': 80, 'n_epochs': 50, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 - SVD Grid Search # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our previous model was overfit, as the test RMSE was higher than the train RMSE. I will lower n_factors and n_epochs in attempt to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 140, 'n_epochs': 50, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [80, 100, 110, 120, 130, 140],\n",
    "          'n_epochs': [20, 30, 40, 50, 60, 70, 80],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd_2 = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd_2.fit(data)\n",
    "g_s_svd_2.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8993\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd_2 = SVD(n_factors=140 ,n_epochs=50, init_mean=0, biased=True)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd_2.fit(trainset)\n",
    "predictions_2 = g_s_svd_2.test(testset)\n",
    "g_s_svd_2 = accuracy.rmse(predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_grid_2', .899, {'n_factors': 140, 'n_epochs': 50, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Grid Search #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 160, 'n_epochs': 40, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [110, 120, 130, 140, 160],\n",
    "          'n_epochs': [10, 20, 30, 40, 50, 60, 70, 80],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd_2 = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd_2.fit(data)\n",
    "g_s_svd_2.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9023\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd_3 = SVD(n_factors=160 ,n_epochs=40, init_mean=0, biased=True)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd_3.fit(trainset)\n",
    "predictions_3 = g_s_svd_3.test(testset)\n",
    "g_s_svd_3_rmse = accuracy.rmse(predictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('g_s_svd_3', .902, {'n_factors': 160, 'n_epochs': 40, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 - SVDpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add SVD ++ information here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 50, 'n_epochs': 60, 'init_mean': 0, 'reg_all': 0.02}\n",
      "0.9469360163421675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed:  7.6min finished\n"
     ]
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[5, 10, 20, 30, 40, 50],\n",
    "                  'n_epochs': [20, 30, 40, 50, 60],\n",
    "                    'init_mean':[0, .01, .02, .03],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model.fit(data)\n",
    "print(svd_pp_model.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9114\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model = SVDpp(n_factors=50, n_epochs=60, init_mean=.00, reg_all=.02)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model.fit(trainset)\n",
    "predictions = svd_pp_model.test(testset)\n",
    "svd_pp_model_1 = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_1', .914, {'n_factors': 50, 'n_epochs': 60, 'init_mean': 0, 'reg_all': 0.02} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #7 - SVD ++ Grid Search #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed: 24.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 90, 'n_epochs': 40, 'init_mean': 0, 'reg_all': 0.03}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[50, 70, 90, 120, 140, 150],\n",
    "                  'n_epochs': [20, 40, 60, 80, 100],\n",
    "                    'init_mean':[0, .01, .02, .03],\n",
    "                     'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_2 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_2.fit(data)\n",
    "svd_pp_model_2.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9038\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD\n",
    "svd_pp_model_2 = SVDpp(n_factors=90, n_epochs=40, init_mean=0.0, reg_all=.03)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_2.fit(trainset)\n",
    "predictions = svd_pp_model_2.test(testset)\n",
    "svd_pp_model_2_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_2', .903, {'n_factors': 90, 'n_epochs': 40, 'init_mean': 0, 'reg_all': 0.03})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #8 - SVD++ Grid Search #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    3.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed: 18.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 100, 'n_epochs': 30, 'init_mean': 0.02, 'reg_all': 0.02}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[90, 100, 110, 120, 130],\n",
    "                  'n_epochs': [20, 30, 40, 50, 60, 70],\n",
    "                    'init_mean':[0, .01, .02, .03],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_3 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_3.fit(data)\n",
    "svd_pp_model_3.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8961\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model_3 = SVDpp(n_factors=100, n_epochs=30, init_mean=0.02, reg_all=.02)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_3.fit(trainset)\n",
    "predictions = svd_pp_model_3.test(testset)\n",
    "svd_pp_model_3_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_3', .896, {'n_factors': 100, 'n_epochs': 30, 'init_mean': 0.02, 'reg_all': 0.02})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #9 - SVD PP - Grid Search #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 125, 'n_epochs': 35, 'init_mean': 0.02, 'reg_all': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 864 out of 864 | elapsed:  7.6min finished\n"
     ]
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[120, 125, 130, 140],\n",
    "                  'n_epochs': [5, 10, 15, 20, 30, 35],\n",
    "                    'init_mean':[0, .01, .02, .03],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_4 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_4.fit(data)\n",
    "print(svd_pp_model_4.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8859\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model_4 = SVDpp(n_factors=125, n_epochs=35, init_mean=.02, reg_all=.03)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_4.fit(trainset)\n",
    "predictions = svd_pp_model_4.test(testset)\n",
    "svd_pp_model_4_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_4', 0.885, {'n_factors': 125, 'n_epochs': 35, 'init_mean': 0.02, 'reg_all': 0.03})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #10 - SVD PP - Grid Search #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    4.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1782 out of 1782 | elapsed: 56.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 125, 'n_epochs': 50, 'init_mean': 0.01, 'reg_all': 0.03}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[110, 120, 125, 130, 135, 140, 145, 150, 160],\n",
    "                  'n_epochs': [20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120],\n",
    "                    'init_mean':[0, .01],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_5 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_5.fit(data)\n",
    "svd_pp_model_5.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9093\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model_5 = SVDpp(n_factors=125, n_epochs=50, init_mean=.01, reg_all=.03)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_5.fit(trainset)\n",
    "predictions = svd_pp_model_5.test(testset)\n",
    "svd_pp_model_5_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_5', .911, {'n_factors': 125, 'n_epochs': 50, 'init_mean': 0.01, 'reg_all': 0.03} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #11 - SVD ++ Grid Search #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 6930 out of 6930 | elapsed: 118.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 120, 'n_epochs': 50, 'init_mean': 0.01, 'reg_all': 0.05}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_pp_param_grid = {'n_factors':[90, 100, 105, 110, 115, 120, 125, 130, 135, 140, 150],\n",
    "                  'n_epochs': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90],\n",
    "                    'init_mean':[0, .01, .02],\n",
    "                    'reg_all':[.01, .02, .03, .04, .05]}\n",
    "svd_pp_model_6 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_6.fit(data)\n",
    "svd_pp_model_6.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9127\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model_6 = SVDpp(n_factors=120, n_epochs=50, init_mean=.01, reg_all=.05)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_6.fit(trainset)\n",
    "predictions = svd_pp_model_6.test(testset)\n",
    "svd_pp_model_6_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_6', .912, {'n_factors': 120, 'n_epochs': 50, 'init_mean': 0.01, 'reg_all': 0.05})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #12 - SVD++ Grid Search  #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    5.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    7.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    9.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   11.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   13.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   15.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   17.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 540 out of 540 | elapsed: 24.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 120, 'n_epochs': 80, 'init_mean': 0, 'reg_all': 0.08}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_pp_param_grid = {'n_factors':[120, 130, 140],\n",
    "                  'n_epochs': [80, 90, 100, 120, 130],\n",
    "                    'init_mean':[0, .01, .02],\n",
    "                    'reg_all':[0.02, 0.08, 0.4, 0.6]}\n",
    "svd_pp_model_7 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_7.fit(data)\n",
    "svd_pp_model_7.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9039\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model_7 = SVDpp(n_factors=120, n_epochs=80, reg_all=.08)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_7.fit(trainset)\n",
    "predictions = svd_pp_model_7.test(testset)\n",
    "svd_pp_model_7_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_7', .903, {'n_factors': 120, 'n_epochs': 80, 'init_mean': 0, 'reg_all': 0.08})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploding params and saving to model df dataframe\n",
    "model_params = model_df[\"params\"].apply(pd.Series)\n",
    "model_df_params = pd.merge(model_df, model_params, left_index=True, right_index=True)\n",
    "model_df_params.drop(columns=['params', 0], inplace=True)\n",
    "model_df_params = model_df_params.sort_values(by='rmse', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After comparing all models, the SVD ++ models performed the best in terms of RMSE. Our final model for the collaborative system will be SVD ++. \n",
    "\n",
    "Since the RMSE scores are so close and only vary my .01 for the top performing models. I will test out each of the models to see which results seem to make the most sense. I will test the models using my name as the user, since i completed the survey, in addition to three other users whose ski preferences I am aware of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>biased</th>\n",
       "      <th>init_mean</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>n_factors</th>\n",
       "      <th>reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svd_pp_4</td>\n",
       "      <td>0.885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svd_pp_3</td>\n",
       "      <td>0.896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svd_grid_2</td>\n",
       "      <td>0.899</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g_s_svd_3</td>\n",
       "      <td>0.902</td>\n",
       "      <td>True</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svd_pp_2</td>\n",
       "      <td>0.903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model   rmse biased  init_mean  n_epochs  n_factors  reg_all\n",
       "8    svd_pp_4  0.885    NaN       0.02      35.0      125.0     0.03\n",
       "7    svd_pp_3  0.896    NaN       0.02      30.0      100.0     0.02\n",
       "3  svd_grid_2  0.899   True       0.00      50.0      140.0      NaN\n",
       "4   g_s_svd_3  0.902   True       0.00      40.0      160.0      NaN\n",
       "6    svd_pp_2  0.903    NaN       0.00      40.0       90.0     0.03"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df_params.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8993\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "best_model = SVDpp(n_factors=140, n_epochs=120, init_mean=.01)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "best_model.fit(trainset)\n",
    "predictions = best_model.test(testset)\n",
    "best_model_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7ff683423c70>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "#loading final dataset\n",
    "data_full = Dataset.load_from_df(surprise_df[['user_name', 'ski_resort', 'rating']], reader)\n",
    "\n",
    "#making trainset\n",
    "full_trainset = data_full.build_full_trainset()\n",
    "\n",
    "algo = SVD(n_factors=140, n_epochs=50)\n",
    "algo.fit(full_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVDpp(n_factors=140, n_epochs=120, init_mean=.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative System - Building Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Winter Park</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Arapahoe Basin</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Steamboat</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Copper Mountain</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anon_2</td>\n",
       "      <td>Solitude Mountain</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_name         ski_resort  rating\n",
       "0    anon_1        Winter Park     4.0\n",
       "1    anon_1     Arapahoe Basin     5.0\n",
       "2    anon_1          Steamboat     5.0\n",
       "3    anon_1    Copper Mountain     5.0\n",
       "4    anon_2  Solitude Mountain     5.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anon_1</th>\n",
       "      <td>Winter Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_1</th>\n",
       "      <td>Arapahoe Basin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_1</th>\n",
       "      <td>Steamboat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_1</th>\n",
       "      <td>Copper Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_2</th>\n",
       "      <td>Solitude Mountain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ski_resort\n",
       "user_name                   \n",
       "anon_1           Winter Park\n",
       "anon_1        Arapahoe Basin\n",
       "anon_1             Steamboat\n",
       "anon_1       Copper Mountain\n",
       "anon_2     Solitude Mountain"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving new dataframe with only user information\n",
    "user_df = surprise_df.reset_index()\n",
    "user_df.set_index('user_name', inplace = True)\n",
    "user_df.drop(columns = ['rating', 'index'], inplace =True)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was found on [Google Colab](https://colab.research.google.com/github/singhsidhukuldeep/Recommendation-System/blob/master/Building_Recommender_System_with_Surprise.ipynb#scrollTo=lM7Db2cj7-IZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Starting dump\n",
      ">> Dump done\n",
      "./model.pickle\n"
     ]
    }
   ],
   "source": [
    "#saving trained model\n",
    "from surprise import dump\n",
    "import os\n",
    "\n",
    "model_filename = \"./model.pickle\"\n",
    "\n",
    "print (\">> Starting dump\")\n",
    "\n",
    "# Dump algorithm and reload it.\n",
    "file_name = os.path.expanduser(model_filename)\n",
    "dump.dump(file_name, algo=algo)\n",
    "\n",
    "print (\">> Dump done\")\n",
    "print(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #loading saved model\n",
    "# def load_model(model_filename):\n",
    "#     print (\">> Loading dump\")\n",
    "#     from surprise import dump\n",
    "#     import os\n",
    "#     file_name = os.path.expanduser(model_filename)\n",
    "#     _, loaded_model = dump.load(file_name)\n",
    "#     print (\">> Loaded dump\")\n",
    "#     return loaded_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function #1  - User & Recommendation #  Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shred_recommender():\n",
    "    user = str(input('Name: '))\n",
    "    n_recs = int(input('How many resort recommendations do you want? '))\n",
    "    \n",
    "    have_rated = list(user_df.loc[user, 'ski_resort'])\n",
    "    not_rated = content_df.copy()\n",
    "    not_rated = not_rated.loc[~not_rated['ski_resort'].isin(have_rated)]\n",
    "    not_rated = not_rated.drop_duplicates(subset=['ski_resort'])\n",
    "    not_rated.reset_index(inplace=True)\n",
    "    not_rated['predicted_rating'] = not_rated['ski_resort'].apply(lambda x: algo.predict(user, x).est)\n",
    "    not_rated.sort_values(by='predicted_rating', ascending=False, inplace=True)\n",
    "    not_rated = not_rated[['ski_resort', 'state', 'city', 'sumt', 'drop', 'base', 'intermediate_runs',\n",
    "                          'advanced_runs', 'expert_runs', 'predicted_rating', 'ikon', 'epic',\n",
    "                          'mountain_collective']].copy()\n",
    "    return not_rated.head(n_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Testing\n",
    "\n",
    "After using different models for the main model, I decided to use the hyperparameters associated with SVD Grid Search #6. The other hyperparameters seemed to return too many local small mountains in the results, which myself as well as the other users typically do not go to unless they're close to the main city they live in.\n",
    "\n",
    "I plan to send the recommendations to the users below and to get their feedback.\n",
    "\n",
    "#### User #1 - Stephanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>state</th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>user_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>New York</td>\n",
       "      <td>Hunter Mountain</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Very crowded and snow quality is typically low...</td>\n",
       "      <td>Stephanie Ciaccia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Vail</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Amazing back bowls and snow. Pricey resort tho...</td>\n",
       "      <td>Stephanie Ciaccia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Snowbird</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazing terrain and huge mountain yet still fe...</td>\n",
       "      <td>Stephanie Ciaccia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Breckenridge</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great bus route that makes the mountain easily...</td>\n",
       "      <td>Stephanie Ciaccia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Park City Mountain</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great terrain, close to airport, but lodging i...</td>\n",
       "      <td>Stephanie Ciaccia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_date     state          ski_resort  rating  \\\n",
       "36  2023-05-05  New York     Hunter Mountain     1.0   \n",
       "37  2023-05-05  Colorado                Vail     4.0   \n",
       "38  2023-05-05      Utah            Snowbird     5.0   \n",
       "39  2023-05-05  Colorado        Breckenridge     4.0   \n",
       "40  2023-05-05      Utah  Park City Mountain     4.0   \n",
       "\n",
       "                                               review          user_name  \n",
       "36  Very crowded and snow quality is typically low...  Stephanie Ciaccia  \n",
       "37  Amazing back bowls and snow. Pricey resort tho...  Stephanie Ciaccia  \n",
       "38  Amazing terrain and huge mountain yet still fe...  Stephanie Ciaccia  \n",
       "39  Great bus route that makes the mountain easily...  Stephanie Ciaccia  \n",
       "40  Great terrain, close to airport, but lodging i...  Stephanie Ciaccia  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_user_df.loc[final_user_df[\"user_name\"] == \"Stephanie Ciaccia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Stephanie Ciaccia\n",
      "How many resort recommendations do you want? 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>sumt</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ikon</th>\n",
       "      <th>epic</th>\n",
       "      <th>mountain_collective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Lutsen Mountains</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Lutsen</td>\n",
       "      <td>1688</td>\n",
       "      <td>825</td>\n",
       "      <td>800</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>4.730035</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Telluride</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Telluride</td>\n",
       "      <td>13150</td>\n",
       "      <td>4425</td>\n",
       "      <td>8725</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>4.615805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Ski Brule</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Iron River</td>\n",
       "      <td>1860</td>\n",
       "      <td>500</td>\n",
       "      <td>1360</td>\n",
       "      <td>35</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>4.553813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ski_resort      state        city   sumt  drop  base  \\\n",
       "140  Lutsen Mountains  Minnesota      Lutsen   1688   825   800   \n",
       "279         Telluride   Colorado   Telluride  13150  4425  8725   \n",
       "231         Ski Brule   Michigan  Iron River   1860   500  1360   \n",
       "\n",
       "     intermediate_runs  advanced_runs  expert_runs  predicted_rating  ikon  \\\n",
       "140                 58             24            8          4.730035     0   \n",
       "279                 30             21           34          4.615805     0   \n",
       "231                 35             24            6          4.553813     0   \n",
       "\n",
       "     epic  mountain_collective  \n",
       "140     0                    0  \n",
       "279     0                    0  \n",
       "231     0                    0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shred_recommender()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User #2 - Raghava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>state</th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>user_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Breckenridge</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Breck is a decent resort, but a lot of the ter...</td>\n",
       "      <td>Raghava Kamalesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Crested Butte Mountain</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Really amazing and extensive terrain for advan...</td>\n",
       "      <td>Raghava Kamalesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Vail</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I enjoyed Vail a lot more this time than my la...</td>\n",
       "      <td>Raghava Kamalesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Beaver Creek</td>\n",
       "      <td>3.0</td>\n",
       "      <td>There are some good runs here, and part of my ...</td>\n",
       "      <td>Raghava Kamalesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2023-05-10</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Telluride</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Telluride is amazing. The town has very good f...</td>\n",
       "      <td>Raghava Kamalesh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_date     state              ski_resort  rating  \\\n",
       "55  2023-05-10  Colorado            Breckenridge     4.0   \n",
       "56  2023-05-10  Colorado  Crested Butte Mountain     5.0   \n",
       "57  2023-05-10  Colorado                    Vail     5.0   \n",
       "58  2023-05-10  Colorado            Beaver Creek     3.0   \n",
       "59  2023-05-10  Colorado               Telluride     5.0   \n",
       "\n",
       "                                               review         user_name  \n",
       "55  Breck is a decent resort, but a lot of the ter...  Raghava Kamalesh  \n",
       "56  Really amazing and extensive terrain for advan...  Raghava Kamalesh  \n",
       "57  I enjoyed Vail a lot more this time than my la...  Raghava Kamalesh  \n",
       "58  There are some good runs here, and part of my ...  Raghava Kamalesh  \n",
       "59  Telluride is amazing. The town has very good f...  Raghava Kamalesh  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_user_df.loc[final_user_df[\"user_name\"] == \"Raghava Kamalesh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Raghava Kamalesh\n",
      "How many resort recommendations do you want? 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>sumt</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ikon</th>\n",
       "      <th>epic</th>\n",
       "      <th>mountain_collective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Whiteface Mountain</td>\n",
       "      <td>New York</td>\n",
       "      <td>Wilngton</td>\n",
       "      <td>4650</td>\n",
       "      <td>3430</td>\n",
       "      <td>1220</td>\n",
       "      <td>46</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4.833741</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Wildcat Mountain</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>4062</td>\n",
       "      <td>2112</td>\n",
       "      <td>1950</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>4.829843</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Lutsen Mountains</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Lutsen</td>\n",
       "      <td>1688</td>\n",
       "      <td>825</td>\n",
       "      <td>800</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>4.787397</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ski_resort          state      city  sumt  drop  base  \\\n",
       "302  Whiteface Mountain       New York  Wilngton  4650  3430  1220   \n",
       "307    Wildcat Mountain  New Hampshire   Jackson  4062  2112  1950   \n",
       "139    Lutsen Mountains      Minnesota    Lutsen  1688   825   800   \n",
       "\n",
       "     intermediate_runs  advanced_runs  expert_runs  predicted_rating  ikon  \\\n",
       "302                 46             31            0          4.833741     0   \n",
       "307                 46             33            0          4.829843     0   \n",
       "139                 58             24            8          4.787397     0   \n",
       "\n",
       "     epic  mountain_collective  \n",
       "302     0                    0  \n",
       "307     1                    0  \n",
       "139     0                    0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shred_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Breckenridge', 'Crested Butte Mountain', 'Vail', 'Beaver Creek', 'Telluride']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(user_df.loc['Raghava Kamalesh', 'ski_resort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alexandria Kelly\n",
      "How many resort recommendations do you want? 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>sumt</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ikon</th>\n",
       "      <th>epic</th>\n",
       "      <th>mountain_collective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Alta</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Alta</td>\n",
       "      <td>11068.0</td>\n",
       "      <td>2538.0</td>\n",
       "      <td>8530.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.646657</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Kirkwood</td>\n",
       "      <td>California</td>\n",
       "      <td>Kirkwood</td>\n",
       "      <td>9800.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>7800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.555924</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mt. Baker</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Bellingham</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.515822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ski_resort       state        city     sumt    drop    base  \\\n",
       "16       Alta        Utah        Alta  11068.0  2538.0  8530.0   \n",
       "54   Kirkwood  California    Kirkwood   9800.0  2000.0  7800.0   \n",
       "18  Mt. Baker  Washington  Bellingham   5000.0  1500.0  3500.0   \n",
       "\n",
       "    intermediate_runs  advanced_runs  expert_runs  predicted_rating  ikon  \\\n",
       "16                0.0            0.0          0.0          4.646657   1.0   \n",
       "54                0.0            0.0          0.0          4.555924   0.0   \n",
       "18                0.0            0.0          0.0          4.515822   0.0   \n",
       "\n",
       "    epic  mountain_collective  \n",
       "16   0.0                  1.0  \n",
       "54   1.0                  0.0  \n",
       "18   0.0                  0.0  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shred_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stevens Pass', 'Vail', 'Snowbird', 'Park City Mountain']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(user_df.loc['Alexandria Kelly', 'ski_resort'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function #2  - User, Recommendation #, and State Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shred_recommender_state():\n",
    "    user = str(input('Name: '))\n",
    "    n_recs = int(input('How many resort recommendations do you want? '))\n",
    "    state = str(input('What state would you like to shred in? '))\n",
    "    \n",
    "    have_rated = list(user_df.loc[user, 'ski_resort'])\n",
    "    not_rated = content_df.copy()\n",
    "    not_rated = not_rated.loc[~not_rated['ski_resort'].isin(have_rated) & (not_rated['state'] == state)]\n",
    "    not_rated = not_rated.drop_duplicates(subset=['ski_resort'])\n",
    "    not_rated.reset_index(inplace=True)\n",
    "    not_rated['predicted_rating'] = not_rated['ski_resort'].apply(lambda x: algo.predict(user, x).est)\n",
    "    not_rated.sort_values(by='predicted_rating', ascending=False, inplace=True)\n",
    "    not_rated = not_rated[['ski_resort', 'state', 'city', 'sumt', 'drop', 'base', 'intermediate_runs',\n",
    "                          'advanced_runs', 'expert_runs', 'predicted_rating', 'ikon', 'epic',\n",
    "                          'mountain_collective']].copy()\n",
    "    return not_rated.head(n_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Stephanie Ciaccia\n",
      "How many resort recommendations do you want? 3\n",
      "What state would you like to shred in? Utah\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>sumt</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ikon</th>\n",
       "      <th>epic</th>\n",
       "      <th>mountain_collective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Snowbasin</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>9350</td>\n",
       "      <td>2900</td>\n",
       "      <td>6450</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>4.434722</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>10500</td>\n",
       "      <td>1745</td>\n",
       "      <td>8755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.297999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brian Head</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Brian Head</td>\n",
       "      <td>10970</td>\n",
       "      <td>1548</td>\n",
       "      <td>9600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.161893</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ski_resort state        city   sumt  drop  base  intermediate_runs  \\\n",
       "8   Snowbasin  Utah  Huntsville   9350  2900  6450                 33   \n",
       "3    Brighton  Utah    Brighton  10500  1745  8755                  0   \n",
       "2  Brian Head  Utah  Brian Head  10970  1548  9600                  0   \n",
       "\n",
       "   advanced_runs  expert_runs  predicted_rating  ikon  epic  \\\n",
       "8             52            6          4.434722     1     0   \n",
       "3              0            0          4.297999     1     0   \n",
       "2              0            0          4.161893     0     0   \n",
       "\n",
       "   mountain_collective  \n",
       "8                    1  \n",
       "3                    0  \n",
       "2                    0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shred_recommender_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
