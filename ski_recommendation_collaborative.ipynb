{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avant Ski/ Send It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by: Stephanie Ciaccia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skiing holds a prominent place for those seeking winter recreational activities in the United States. With its stunning mountain ranges and diverse terrain, the country boasts numerous ski resorts that cater to all skill levels, from beginners to seasoned professionals. Skiing offers a unique blend of adventure, physical activity, and natural beauty, making it a popular choice for winter enthusiasts seeking both relaxation and excitement.\n",
    "\n",
    "The ski market in the United States is thriving, contributing significantly to the economy. According to the [National Ski Areas Association (NSAA)](chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://nsaa.org/webdocs/Media_Public/IndustryStats/Historical_Skier_Days_1979_2022.pdf), approximately 60.7 million skiers and snowboarders visited 473 ski resorts in the 2021-2022 winter season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skiing, an exhilarating winter sport cherished by many, often involves time-consuming and daunting trip planning. The sheer abundance of ski resorts available makes it overwhelming to choose the ideal destination, and existing ski websites lack the necessary tools to filter options based on individual preferences.\n",
    "\n",
    "To address these challenges, I'm developing Avant Ski, a ski resort recommendation app. Avant Ski simplifies the ski resort selection process by leveraging data and user preferences. With dynamic filtering features, users can personalize their search based on budget, location, amenities, and skill level. By bridging the gap between ski enthusiasts and their dream destinations, Avant Ski makes skiing accessible to a wider audience, empowering them to plan unforgettable ski trips with confidence.\n",
    "\n",
    "Since data plays a crucial role in this application, I plan to showcase the app to representatives from different ski resorts across the USA at the National Ski Area Association Winter Confernce. This presentation aims to foster partnerships and encourage resort feature sharing between Avant Ski and these resorts once the app is launched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline, KNNWithZScore,  SVD, SVDpp, NMF, BaselineOnly, CoClustering, SlopeOne, NormalPredictor\n",
    "from surprise.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from IPython.display import Image, display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to print full rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_full(x):\n",
    "    pd.set_option('display.max_rows', len(x))\n",
    "    print(x)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_user_df = pd.read_csv(\"data/cleaned_data_exports/user_df_model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_df = pd.read_csv(\"data/cleaned_data_exports/scraped_feature_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling - Recommendation System\n",
    "The proposed recommendation system will adopt a cascade hybrid approach, integrating user-based filtering and content-based recommendation systems.\n",
    "\n",
    "This **cascade hybrid** approach establishes a hierarchical structure within the recommendation system. The primary model, a collaborative user-based system, will generate the initial set of recommendations based on user preferences and ratings. Then, a secondary model, a content-based system, will refine the recommendations by considering additional factors such as mountain characteristics and user-defined filters. This two-step process aims to provide more accurate and personalized ski resort suggestions.\n",
    "\n",
    "In the **user-based collaborative** filtering phase, the model will analyze the historical ratings of users for different ski resorts. By identifying users with similar rating patterns, the model will predict the target user's ratings for unvisited resorts, leveraging the collective wisdom of similar users.\n",
    "\n",
    "The **content-based system** operates by constructing a matrix of resort features and determining the similarity between resorts based on these features. This approach allows the system to identify resorts with similar characteristics and recommend them based on user preferences.\n",
    "\n",
    "To evaluate the accuracy of the collaborative model, the **Root Mean Square Error (RMSE)** score will be used. This metric quantifies the difference between the actual ratings and the predicted ratings, providing insights into the model's performance in capturing user preferences.\n",
    "\n",
    "While the content-based system does not have an accuracy score, a combination of ski expertise and specific user information will be utilized to subjectively assess the effectiveness of the hybrid model.\n",
    "\n",
    "By utilizing both user-based and content-based approaches, the cascade hybrid recommendation system aims to enhance the ski resort selection process, **offering users more personalized and relevant recommendations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise Data\n",
    "To make this model, we will be using the python package Surprise. This is a scikit tool that uses a range of algorithms made up of matrix factorization-based methods for collaborative filtering. \n",
    "\n",
    "To begin, we will make new dataframe from our final cleaned dataframe with three columns that include user **id, ratings, and movie ids.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_user_df.drop(columns=\"Unnamed: 0\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    979\n",
       "4    888\n",
       "3    390\n",
       "2    175\n",
       "1     89\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_user_df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copying final rewview dataframe\n",
    "surprise_df = final_user_df.copy()\n",
    "\n",
    "#dropping unneeded columns\n",
    "surprise_df = surprise_df[['user_name', 'ski_resort', 'rating']]\n",
    "\n",
    "#saving final surprise_df\n",
    "surprise_df.to_csv(\"data/cleaned_data_exports/surprise_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Winter Park</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Arapahoe Basin</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Steamboat</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Copper Mountain</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anon_2</td>\n",
       "      <td>Solitude Mountain</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>John undefined</td>\n",
       "      <td>Bridger Bowl</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>Daniel undefined</td>\n",
       "      <td>Blacktail Mountain</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>Daniel undefined</td>\n",
       "      <td>Blacktail Mountain</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>Whitefish Mountain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Steve undefined</td>\n",
       "      <td>Ski Apache</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2521 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_name          ski_resort  rating\n",
       "0               anon_1         Winter Park       4\n",
       "1               anon_1      Arapahoe Basin       5\n",
       "2               anon_1           Steamboat       5\n",
       "3               anon_1     Copper Mountain       5\n",
       "4               anon_2   Solitude Mountain       5\n",
       "...                ...                 ...     ...\n",
       "2516    John undefined        Bridger Bowl       5\n",
       "2517  Daniel undefined  Blacktail Mountain       5\n",
       "2518  Daniel undefined  Blacktail Mountain       5\n",
       "2519         Elizabeth  Whitefish Mountain       1\n",
       "2520   Steve undefined          Ski Apache       1\n",
       "\n",
       "[2521 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "#loading final dataset\n",
    "data = Dataset.load_from_df(surprise_df[['user_name', 'ski_resort', 'rating']], reader)\n",
    "\n",
    "#spltting into train and test\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  532 \n",
      "\n",
      "Number of items:  264\n"
     ]
    }
   ],
   "source": [
    "#looking at number of users\n",
    "print('Number of users: ', trainset.n_users, '\\n')\n",
    "print('Number of items: ', trainset.n_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Predictor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal Predictor baseline model's Root Mean Squared Error (RMSE) tells us that our predicted rating is **1.41** points away from the actual rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3994\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "baseline = NormalPredictor()\n",
    "\n",
    "#fitting model\n",
    "baseline.fit(trainset)\n",
    "\n",
    "# making prediction on testset\n",
    "predictions = baseline.test(testset)\n",
    "\n",
    "# Save RMSE score\n",
    "baseline_normal = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving normal rmse\n",
    "test_baseline_normal_rmse = 1.399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rmse = [['normal predictor', 1.399, 'n/a']]\n",
    "\n",
    "model_df = pd.DataFrame(data_rmse, columns=['model', 'rmse', 'params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal predictor</td>\n",
       "      <td>1.399</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model   rmse params\n",
       "0  normal predictor  1.399    n/a"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function to save the RMSE for all model iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_comp(model_name, rmse, params):\n",
    "    model_df.loc[len(model_df.index)] = [model_name, rmse, params] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal Predictor baseline model's Root Mean Squared Error (RMSE) tells us that our predicted rating is **1.41** points away from the actual rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithim Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, I'll be testing all algorithms available in Surprise to deterime which models I should I should further adjust hyperparameters.\n",
    "\n",
    "This code was adapated from this [blog](https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n"
     ]
    }
   ],
   "source": [
    "benchmark = []\n",
    "\n",
    "# Iterate over all algorithms to see which performs beset\n",
    "for algorithm in [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), BaselineOnly(), CoClustering()]:\n",
    "    \n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "benchmark_df = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.962886</td>\n",
       "      <td>0.086641</td>\n",
       "      <td>0.003666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.977763</td>\n",
       "      <td>0.186876</td>\n",
       "      <td>0.009264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.994478</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.012054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaselineOnly</th>\n",
       "      <td>0.997223</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>1.019341</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.009150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>1.155632</td>\n",
       "      <td>0.060120</td>\n",
       "      <td>0.002458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>1.164038</td>\n",
       "      <td>0.015831</td>\n",
       "      <td>0.010955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>1.178665</td>\n",
       "      <td>0.007177</td>\n",
       "      <td>0.010117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>1.188278</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.003930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>1.188651</td>\n",
       "      <td>0.110433</td>\n",
       "      <td>0.005485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>1.405616</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.003329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "SVD               0.962886  0.086641   0.003666\n",
       "SVDpp             0.977763  0.186876   0.009264\n",
       "KNNBaseline       0.994478  0.006389   0.012054\n",
       "BaselineOnly      0.997223  0.001697   0.001988\n",
       "KNNBasic          1.019341  0.004235   0.009150\n",
       "CoClustering      1.155632  0.060120   0.002458\n",
       "KNNWithZScore     1.164038  0.015831   0.010955\n",
       "KNNWithMeans      1.178665  0.007177   0.010117\n",
       "SlopeOne          1.188278  0.004408   0.003930\n",
       "NMF               1.188651  0.110433   0.005485\n",
       "NormalPredictor   1.405616  0.001390   0.003329"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the intiial test, SVDpp and SVD had the lowerse RMSE scores. I will start adjusting hyperparameters to see which model will perform the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1 - SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using Singular Value Decomposition (SVD) to reduce the dimensionality of our matrix. SVD is a matrix factorization model that decomposes the reviewer reviews and resort into three matrices (user name, review, and rating). This helps us understand the relationship between users and items, or in this case users and ski resorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "RMSE (testset)    0.9697  0.9805  0.9630  0.9710  0.0072  \n",
      "Fit time          0.10    0.08    0.08    0.09    0.01    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    \n"
     ]
    }
   ],
   "source": [
    "# Cross validate a basic SVD with no hyperparameter tuning expecting sub-par results\n",
    "svd_basic = SVD(random_state=42)\n",
    "\n",
    "results = cross_validate(svd_basic, data, measures=['RMSE'], cv=3, n_jobs = -1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9480\n"
     ]
    }
   ],
   "source": [
    "# Fit to trainset and predict on the testset for evaluation\n",
    "svd_basic.fit(trainset)\n",
    "\n",
    "predictions = svd_basic.test(testset)\n",
    "\n",
    "svd_simple = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd', .948, 'n/a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2 - SVD Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, I will be adjusting the following parameters:\n",
    "\n",
    " - n_factors - Increasing the number of factors can improve the model's ability to capture user and content interactions more accurately\n",
    " - n_epochs - Changes the number of iterations the model performs on the training data\n",
    " - init_mean - It changes the starting point for factor initilization\n",
    " - biased - Since user bias is a common issue with ratings, this parameter accounts for more inherent bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 140, 'n_epochs': 40, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [100, 120, 140],\n",
    "          'n_epochs': [20, 40, 60, 80, 100, 120],\n",
    "          'init_mean': [0,.01, 0.05],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd.fit(data)\n",
    "g_s_svd.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9105\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd = SVD(n_factors=140 ,n_epochs=40, init_mean=0, biased=True)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd.fit(trainset)\n",
    "predictions = g_s_svd.test(testset)\n",
    "g_s_svd_1 = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_grid_1', .9105, {'n_factors': 140, 'n_epochs': 40, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 - SVD Grid Search # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will continue to adjust the hyperparameters to see if we can bring down the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 80, 'n_epochs': 90, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [20, 30, 40, 50, 60, 70, 80],\n",
    "          'n_epochs': [70, 80, 90, 100, 120, 130],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd_2 = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd_2.fit(data)\n",
    "g_s_svd_2.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9171\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd_2 = SVD(n_factors=80 ,n_epochs=90, init_mean=0, biased=True)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd_2.fit(trainset)\n",
    "predictions_2 = g_s_svd_2.test(testset)\n",
    "g_s_svd_2 = accuracy.rmse(predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_grid_2', .917, {'n_factors': 80, 'n_epochs': 90, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Grid Search #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am slightly adjusting the number of n_factors and n_epochs to see if this will bring down RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 120, 'n_epochs': 60, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [110, 120, 130, 140, 160],\n",
    "          'n_epochs': [10, 20, 30, 40, 50, 60, 70, 80],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd_2 = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd_2.fit(data)\n",
    "g_s_svd_2.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9143\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd_3 = SVD(n_factors=120 ,n_epochs=60, init_mean=0, biased=True)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd_3.fit(trainset)\n",
    "predictions_3 = g_s_svd_3.test(testset)\n",
    "g_s_svd_3_rmse = accuracy.rmse(predictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('g_s_svd_3', .914, {'n_factors': 120, 'n_epochs': 60, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Grid Search #4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 90, 'n_epochs': 50, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [90, 100, 105, 110, 115, 120],\n",
    "          'n_epochs': [5, 10, 20, 30, 40, 50, 60, 70],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd_4 = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd_4.fit(data)\n",
    "g_s_svd_4.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9103\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd_4 = SVD(n_factors=90 ,n_epochs=50, init_mean=0, biased=True)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd_4.fit(trainset)\n",
    "predictions_4 = g_s_svd_4.test(testset)\n",
    "g_s_svd_4_rmse = accuracy.rmse(predictions_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('g_s_svd_4', .910, {'n_factors': 90, 'n_epochs': 50, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Grid Search #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 90, 'n_epochs': 70, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [40, 50, 60, 70, 80, 90],\n",
    "          'n_epochs': [30, 40, 50, 60, 70, 80, 90, 100],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd_5 = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd_5.fit(data)\n",
    "g_s_svd_5.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9016\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd_5 = SVD(n_factors=90 ,n_epochs=70, init_mean=0, biased=True)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd_5.fit(trainset)\n",
    "predictions_5 = g_s_svd_5.test(testset)\n",
    "g_s_svd_5_rmse = accuracy.rmse(predictions_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('g_s_svd_5', .901, {'n_factors': 90, 'n_epochs': 70, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 130, 'n_epochs': 50, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [115, 120, 125, 130, 135, 140],\n",
    "          'n_epochs': [20, 30, 40, 50, 60, 70],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd_6 = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd_6.fit(data)\n",
    "g_s_svd_6.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9149\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd_6 = SVD(n_factors=130 ,n_epochs=50, init_mean=0, biased=True, random_state=42)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd_6.fit(trainset)\n",
    "predictions_6 = g_s_svd_6.test(testset)\n",
    "g_s_svd_6_rmse = accuracy.rmse(predictions_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('g_s_svd_6', .914, {'n_factors': 130, 'n_epochs': 50, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_factors': 125, 'n_epochs': 60, 'init_mean': 0, 'biased': True}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test grid search\n",
    "params = {'n_factors': [115, 120, 125, 127, 130, 135, 140, 145],\n",
    "          'n_epochs': [10, 20, 25, 30, 35, 40, 45, 50, 60, 70],\n",
    "          'init_mean': [-0.5, 0, 0.5],\n",
    "         'biased': [True, False]}\n",
    "\n",
    "g_s_svd_7 = GridSearchCV(SVD, param_grid=params, cv=5, refit=True)\n",
    "\n",
    "g_s_svd_7.fit(data)\n",
    "g_s_svd_7.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9041\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD with best hyperparameters from gridsearch\n",
    "g_s_svd_7 = SVD(n_factors=125 ,n_epochs=60, init_mean=0, biased=True, random_state=42)\n",
    "\n",
    "# fit on trainset and make predictions using testset\n",
    "g_s_svd_7.fit(trainset)\n",
    "predictions_7 = g_s_svd_7.test(testset)\n",
    "g_s_svd_7_rmse = accuracy.rmse(predictions_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('g_s_svd_7', .904, {'n_factors': 125, 'n_epochs': 60, 'init_mean': 0, 'biased': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #3 - SVDpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD++ is SVD with Implicit Feedback, which incorporates implicit feedback information into the model which capture additional user preferences and can improve the accuracy of the model.\n",
    "\n",
    "SVD++ was the top performing model in the initial benchmark selection, so I am expecting this model to perform the best.\n",
    "\n",
    " - n_factors - Increasing the number of factors can improve the model's ability to capture user and content interactions more accurately\n",
    " - n_epochs - Changes the number of iterations the model performs on the training data\n",
    " - init_mean - It changes the starting point for factor initilization\n",
    " - reg-all - This is a regularization term that's applied to all parameters and helps prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin I will start with a lower n_factors and n_epochs. Larger n_factors numbers can lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 50, 'n_epochs': 30, 'init_mean': 0, 'reg_all': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed:  7.8min finished\n"
     ]
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[5, 10, 20, 30, 40, 50],\n",
    "                  'n_epochs': [20, 30, 40, 50, 60],\n",
    "                    'init_mean':[0, .01, .02, .03],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model.fit(data)\n",
    "print(svd_pp_model.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9116\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model = SVDpp(n_factors=50, n_epochs=30, init_mean=.0, reg_all=.03)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model.fit(trainset)\n",
    "predictions = svd_pp_model.test(testset)\n",
    "svd_pp_model_1 = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_1', .9116, {'n_factors': 50, 'n_epochs': 30, 'init_mean': 0.0, 'reg_all': 0.03} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #7 - SVD ++ Grid Search #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last SVD++ model had a slightly lower RMSE than the SVD models. I am going to increase the n_factors to increase the complexity of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed: 24.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 90, 'n_epochs': 20, 'init_mean': 0, 'reg_all': 0.03}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[50, 70, 90, 120, 140, 150],\n",
    "                  'n_epochs': [20, 40, 60, 80, 100],\n",
    "                    'init_mean':[0, .01, .02, .03],\n",
    "                     'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_2 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_2.fit(data)\n",
    "svd_pp_model_2.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9176\n"
     ]
    }
   ],
   "source": [
    "# instantiating SVD\n",
    "svd_pp_model_2 = SVDpp(n_factors=90, n_epochs=20, init_mean=0, reg_all=.03)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_2.fit(trainset)\n",
    "predictions = svd_pp_model_2.test(testset)\n",
    "svd_pp_model_2_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_2', .917, {'n_factors': 120, 'n_epochs': 20, 'init_mean': 0.2, 'reg_all': 0.03})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #8 - SVD++ Grid Search #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous model performed slightly worse than the first SVD ++ model. I am now going to adjust the n_factors and n_epochs by making the steps inbetween the numbers smaller in attempt to capture the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1440 out of 1440 | elapsed: 20.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 90, 'n_epochs': 30, 'init_mean': 0.01, 'reg_all': 0.03}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[90, 100, 110, 120, 130],\n",
    "                  'n_epochs': [5, 10, 20, 30, 40, 50, 60, 70],\n",
    "                    'init_mean':[0, .01, .02, .03],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_3 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_3.fit(data)\n",
    "svd_pp_model_3.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9148\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model_3 = SVDpp(n_factors=90, n_epochs=30, init_mean=0.01, reg_all=.03)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_3.fit(trainset)\n",
    "predictions = svd_pp_model_3.test(testset)\n",
    "svd_pp_model_3_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_3', .9148, {'n_factors': 90, 'n_epochs': 30, 'init_mean': 0.01, 'reg_all': 0.03})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #9 - SVD PP - Grid Search #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last model performed slightly worse than the previous model. I'm going to adjust the n_factors and n_epochs again by further adjusting the distance between the parameter options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 125, 'n_epochs': 20, 'init_mean': 0, 'reg_all': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 864 out of 864 | elapsed:  7.6min finished\n"
     ]
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[120, 125, 130, 140],\n",
    "                  'n_epochs': [5, 10, 15, 20, 30, 35],\n",
    "                    'init_mean':[0, .01, .02, .03],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_4 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_4.fit(data)\n",
    "print(svd_pp_model_4.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9299\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model_4 = SVDpp(n_factors=125, n_epochs=20, init_mean=.0, reg_all=.01)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_4.fit(trainset)\n",
    "predictions = svd_pp_model_4.test(testset)\n",
    "svd_pp_model_4_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_4', 0.929, {'n_factors': 125, 'n_epochs': 20, 'init_mean': 0.0, 'reg_all': 0.01})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #10 - SVD PP - Grid Search #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    2.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    2.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    3.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    4.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 1782 out of 1782 | elapsed: 56.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 125, 'n_epochs': 50, 'init_mean': 0.01, 'reg_all': 0.03}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[110, 120, 125, 130, 135, 140, 145, 150, 160],\n",
    "                  'n_epochs': [20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120],\n",
    "                    'init_mean':[0, .01],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_5 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_5.fit(data)\n",
    "svd_pp_model_5.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 882 out of 882 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_factors': 70, 'n_epochs': 40, 'init_mean': 0.01, 'reg_all': 0.02}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New hyperparameter dictionary for nmf model\n",
    "svd_pp_param_grid = {'n_factors':[10, 20, 30, 40, 50, 60, 70],\n",
    "                  'n_epochs': [10, 20, 30, 40, 50, 60, 70],\n",
    "                    'init_mean':[0, .01],\n",
    "                    'reg_all':[.01, .02, .03]}\n",
    "svd_pp_model_5 = GridSearchCV(SVDpp, param_grid=svd_pp_param_grid, cv=3, joblib_verbose=10, return_train_measures=True)\n",
    "\n",
    "# Fit and return the best hyperparameters\n",
    "svd_pp_model_5.fit(data)\n",
    "svd_pp_model_5.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9165\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "svd_pp_model_5 = SVDpp(n_factors=70, n_epochs=40, init_mean=.01, reg_all=.02)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "svd_pp_model_5.fit(trainset)\n",
    "predictions = svd_pp_model_5.test(testset)\n",
    "svd_pp_model_5_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comp('svd_pp_5', .916, {'n_factors': 70, 'n_epochs': 40, 'init_mean': 0.01, 'reg_all': 0.02} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model was the final SVD Grid Search #4 that gave us a RMSE of .90.\n",
    "\n",
    "- n_factors = 125\n",
    "- n_epochs = .60\n",
    "- biased = True\n",
    "\n",
    "The RMSE scores for the top performing models were all very close, so I trained multiple models and tested the function to see which performed the best. After testing the functions with three users, two of which filled out the google survey, I decided to use the hyperparameters associated with SVD Grid Search #4.\n",
    "\n",
    "The other models more often returned resorts that were not aligned with the users top rated resorts in terms of mountain characteristics and features. There were some instances where some of the recommendations did seem off, however the content based model should compensate for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rmse</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>g_s_svd_5</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>{'n_factors': 90, 'n_epochs': 70, 'init_mean':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>g_s_svd_6</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>{'n_factors': 130, 'n_epochs': 50, 'init_mean'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svd_pp_1</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>{'n_factors': 50, 'n_epochs': 50, 'init_mean':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>g_s_svd_7</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>{'n_factors': 125, 'n_epochs': 60, 'init_mean'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>g_s_svd_4</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>{'n_factors': 90, 'n_epochs': 50, 'init_mean':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svd_grid_1</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>{'n_factors': 140, 'n_epochs': 40, 'init_mean'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svd_grid_2</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>{'n_factors': 140, 'n_epochs': 40, 'init_mean'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g_s_svd_3</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>{'n_factors': 120, 'n_epochs': 60, 'init_mean'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>g_s_svd_6</td>\n",
       "      <td>0.9140</td>\n",
       "      <td>{'n_factors': 130, 'n_epochs': 50, 'init_mean'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>svd_pp_3</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>{'n_factors': 90, 'n_epochs': 30, 'init_mean':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svd_pp_5</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>{'n_factors': 70, 'n_epochs': 40, 'init_mean':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>svd_grid_2</td>\n",
       "      <td>0.9170</td>\n",
       "      <td>{'n_factors': 80, 'n_epochs': 90, 'init_mean':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>svd_pp_2</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>{'n_factors': 120, 'n_epochs': 20, 'init_mean'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svd_pp_4</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>{'n_factors': 125, 'n_epochs': 20, 'init_mean'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svd</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal predictor</td>\n",
       "      <td>1.3990</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model    rmse  \\\n",
       "12         g_s_svd_5  0.9010   \n",
       "13         g_s_svd_6  0.9010   \n",
       "5           svd_pp_1  0.9030   \n",
       "15         g_s_svd_7  0.9040   \n",
       "11         g_s_svd_4  0.9100   \n",
       "2         svd_grid_1  0.9105   \n",
       "3         svd_grid_2  0.9140   \n",
       "4          g_s_svd_3  0.9140   \n",
       "14         g_s_svd_6  0.9140   \n",
       "7           svd_pp_3  0.9148   \n",
       "9           svd_pp_5  0.9160   \n",
       "10        svd_grid_2  0.9170   \n",
       "6           svd_pp_2  0.9230   \n",
       "8           svd_pp_4  0.9290   \n",
       "1                svd  0.9480   \n",
       "0   normal predictor  1.3990   \n",
       "\n",
       "                                               params  \n",
       "12  {'n_factors': 90, 'n_epochs': 70, 'init_mean':...  \n",
       "13  {'n_factors': 130, 'n_epochs': 50, 'init_mean'...  \n",
       "5   {'n_factors': 50, 'n_epochs': 50, 'init_mean':...  \n",
       "15  {'n_factors': 125, 'n_epochs': 60, 'init_mean'...  \n",
       "11  {'n_factors': 90, 'n_epochs': 50, 'init_mean':...  \n",
       "2   {'n_factors': 140, 'n_epochs': 40, 'init_mean'...  \n",
       "3   {'n_factors': 140, 'n_epochs': 40, 'init_mean'...  \n",
       "4   {'n_factors': 120, 'n_epochs': 60, 'init_mean'...  \n",
       "14  {'n_factors': 130, 'n_epochs': 50, 'init_mean'...  \n",
       "7   {'n_factors': 90, 'n_epochs': 30, 'init_mean':...  \n",
       "9   {'n_factors': 70, 'n_epochs': 40, 'init_mean':...  \n",
       "10  {'n_factors': 80, 'n_epochs': 90, 'init_mean':...  \n",
       "6   {'n_factors': 120, 'n_epochs': 20, 'init_mean'...  \n",
       "8   {'n_factors': 125, 'n_epochs': 20, 'init_mean'...  \n",
       "1                                                 n/a  \n",
       "0                                                 n/a  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.sort_values(by=\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9041\n"
     ]
    }
   ],
   "source": [
    "# instantiating NFM\n",
    "best_model = SVD(n_factors=125 ,n_epochs=60, init_mean=0, biased=True, random_state=42)\n",
    "\n",
    "# Fit on trainset and make predictions using testset to return RMSE metric\n",
    "best_model.fit(trainset)\n",
    "predictions = best_model.test(testset)\n",
    "best_model_rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Full Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating the collaborative mode, we will need to train it on the full dataset. This is important because it ensures that the model learns from the complete set of user resort reviews, so it can make more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7fc560ebbfd0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "#loading final dataset\n",
    "data_full = Dataset.load_from_df(surprise_df[['user_name', 'ski_resort', 'rating']], reader)\n",
    "\n",
    "#making trainset\n",
    "full_trainset = data_full.build_full_trainset()\n",
    "\n",
    "algo = SVD(n_factors=90, n_epochs=70, init_mean=.0, reg_all= 0.0, biased=True)\n",
    "algo.fit(full_trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative System - Building Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the model, we will need to create a function that takes in user inputs and outputs predictions. To start, I will make a dataframe of only the user names, ratings, and ski resorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Winter Park</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Arapahoe Basin</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Steamboat</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anon_1</td>\n",
       "      <td>Copper Mountain</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anon_2</td>\n",
       "      <td>Solitude Mountain</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_name         ski_resort  rating\n",
       "0    anon_1        Winter Park       4\n",
       "1    anon_1     Arapahoe Basin       5\n",
       "2    anon_1          Steamboat       5\n",
       "3    anon_1    Copper Mountain       5\n",
       "4    anon_2  Solitude Mountain       5"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>anon_1</th>\n",
       "      <td>Winter Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_1</th>\n",
       "      <td>Arapahoe Basin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_1</th>\n",
       "      <td>Steamboat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_1</th>\n",
       "      <td>Copper Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anon_2</th>\n",
       "      <td>Solitude Mountain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ski_resort\n",
       "user_name                   \n",
       "anon_1           Winter Park\n",
       "anon_1        Arapahoe Basin\n",
       "anon_1             Steamboat\n",
       "anon_1       Copper Mountain\n",
       "anon_2     Solitude Mountain"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#saving new dataframe with only user information\n",
    "user_df = surprise_df.reset_index()\n",
    "user_df.set_index('user_name', inplace = True)\n",
    "user_df.drop(columns = ['rating', 'index'], inplace =True)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hybrid model and streamlist app, I will need to save the trained model. To do this, I adapted code found on [Google Colab](https://colab.research.google.com/github/singhsidhukuldeep/Recommendation-System/blob/master/Building_Recommender_System_with_Surprise.ipynb#scrollTo=lM7Db2cj7-IZ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Starting dump\n",
      ">> Dump done\n",
      "./model.pickle\n"
     ]
    }
   ],
   "source": [
    "#saving trained model\n",
    "from surprise import dump\n",
    "import os\n",
    "\n",
    "model_filename = \"./model.pickle\"\n",
    "\n",
    "print (\">> Starting dump\")\n",
    "\n",
    "# Dump algorithm and reload it.\n",
    "file_name = os.path.expanduser(model_filename)\n",
    "dump.dump(file_name, algo=algo)\n",
    "\n",
    "print (\">> Dump done\")\n",
    "print(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function #1  - User & Recommendation #  Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function that will be used to take user inputs and return predicted ratings. This will used the final trained SVD++ model. The results will be sorted by the highest ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shred_recommender():\n",
    "    #user input\n",
    "    user = str(input('Name: '))\n",
    "    #number of recommendations\n",
    "    n_recs = int(input('How many resort recommendations do you want? '))\n",
    "    \n",
    "    #making a list of the resorts rated by each user\n",
    "    have_rated = list(user_df.loc[user, 'ski_resort'])\n",
    "    #dropping rated resorts for final recommendation\n",
    "    not_rated = content_df.copy()\n",
    "    not_rated = not_rated.loc[~not_rated['ski_resort'].isin(have_rated)]\n",
    "    not_rated = not_rated.drop_duplicates(subset=['ski_resort'])\n",
    "    not_rated.reset_index(inplace=True)\n",
    "    \n",
    "    #running the model and saving the predicted ratings as a new column\n",
    "    not_rated['predicted_rating'] = not_rated['ski_resort'].apply(lambda x: algo.predict(user, x).est)\n",
    "    not_rated.sort_values(by='predicted_rating', ascending=False, inplace=True)\n",
    "    not_rated = not_rated[['ski_resort', 'state', 'city', 'summit', 'drop', 'base', 'intermediate_runs',\n",
    "                          'advanced_runs', 'expert_runs', 'predicted_rating', 'ikon', 'epic',\n",
    "                          'mountain_collective']].copy()\n",
    "    return not_rated.head(n_recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Testing\n",
    "\n",
    "I will be testing the model results with two users who filled out the resort survey, and who I created a user profile based on a set of questions I asked each user. I removed their last names from the survey.\n",
    "\n",
    "**Alexandria K.**\n",
    "- Dislikes \"bougie\" resorts\n",
    "- Travels to shred\n",
    "- Looks for expert runs and accessible transportation\n",
    "- Buys the Epic pass but dislikes Vail and corporate ski vibes\n",
    "- Budget-friendly planning\n",
    "\n",
    "**Raghava K.**\n",
    "- Loves expert terrain and well- marked tails\n",
    "- All about the apres-ski life \n",
    "- Travels to shred but wants to have fun while doing it\n",
    "- Uses both Epic & Ikon passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function to display user reviews and merging this with the final content dataframe. This will be useful in comparing results with user's rated mountains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a function to review original \n",
    "def user_comp(name):\n",
    "\n",
    "    #saving reviews as a dataframe\n",
    "    user_1_df = final_user_df.loc[final_user_df[\"user_name\"] == name]\n",
    "\n",
    "    #making a list of resort names\n",
    "    user_1_resort_list = user_1_df['ski_resort'].to_list()\n",
    "\n",
    "    #saving as df to review features and compare with review\n",
    "    user_1_df = content_df.loc[content_df['ski_resort'].isin(user_1_resort_list)]\n",
    "    \n",
    "    user_1_df.drop(columns=\"Unnamed: 0\")\n",
    "    \n",
    "    review_df = pd.DataFrame(final_user_df.loc[final_user_df[\"user_name\"] == name])\n",
    "    \n",
    "    review_df = review_df[[\"ski_resort\", \"rating\", \"review\"]]\n",
    "    \n",
    "    user_1_df = user_1_df[['ski_resort', 'state', 'city', 'summit', 'drop', 'base', 'intermediate_runs',\n",
    "                          'advanced_runs', 'expert_runs', 'ikon', 'epic',\n",
    "                          'mountain_collective']]\n",
    "    \n",
    "    return(pd.merge(review_df, user_1_df, on=\"ski_resort\")).drop(columns=['ikon', 'epic', 'mountain_collective'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User #1 - Raghava K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first user rated large mountains with advanced, expert, runs and good transportation highly. Their lowest score was given to a mountain that did not have good signage and was difficult to get to with public transport.\n",
    "\n",
    "Overall, 4/5 recommendations were similar to the mountains rated in terms of trail difficulty, summit, and drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>summit</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Breckenridge</td>\n",
       "      <td>4</td>\n",
       "      <td>Breck is a decent resort but a lot of the terr...</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Breckenridge</td>\n",
       "      <td>12998</td>\n",
       "      <td>3398</td>\n",
       "      <td>9600</td>\n",
       "      <td>23</td>\n",
       "      <td>36</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crested Butte Mountain</td>\n",
       "      <td>5</td>\n",
       "      <td>Really amazing and extensive terrain for advan...</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Mt. Crested Butte Mountain</td>\n",
       "      <td>12162</td>\n",
       "      <td>3062</td>\n",
       "      <td>9375</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vail</td>\n",
       "      <td>5</td>\n",
       "      <td>I enjoyed Vail a lot more this time than my la...</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Vail</td>\n",
       "      <td>11570</td>\n",
       "      <td>3450</td>\n",
       "      <td>8120</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beaver Creek</td>\n",
       "      <td>3</td>\n",
       "      <td>re are some good runs here and part of my qual...</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Vail</td>\n",
       "      <td>11440</td>\n",
       "      <td>3340</td>\n",
       "      <td>8100</td>\n",
       "      <td>30</td>\n",
       "      <td>24</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Telluride</td>\n",
       "      <td>5</td>\n",
       "      <td>Telluride is amazing  town has very good food ...</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Telluride</td>\n",
       "      <td>13150</td>\n",
       "      <td>4425</td>\n",
       "      <td>8725</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ski_resort  rating  \\\n",
       "0            Breckenridge       4   \n",
       "1  Crested Butte Mountain       5   \n",
       "2                    Vail       5   \n",
       "3            Beaver Creek       3   \n",
       "4               Telluride       5   \n",
       "\n",
       "                                              review     state  \\\n",
       "0  Breck is a decent resort but a lot of the terr...  Colorado   \n",
       "1  Really amazing and extensive terrain for advan...  Colorado   \n",
       "2  I enjoyed Vail a lot more this time than my la...  Colorado   \n",
       "3  re are some good runs here and part of my qual...  Colorado   \n",
       "4  Telluride is amazing  town has very good food ...  Colorado   \n",
       "\n",
       "                         city  summit  drop  base  intermediate_runs  \\\n",
       "0                Breckenridge   12998  3398  9600                 23   \n",
       "1  Mt. Crested Butte Mountain   12162  3062  9375                 25   \n",
       "2                        Vail   11570  3450  8120                 35   \n",
       "3                        Vail   11440  3340  8100                 30   \n",
       "4                   Telluride   13150  4425  8725                 30   \n",
       "\n",
       "   advanced_runs  expert_runs  \n",
       "0             36         28.0  \n",
       "1             25         36.0  \n",
       "2             40          2.0  \n",
       "3             24          8.0  \n",
       "4             21         34.0  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_comp(\"Raghava K.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Raghava K.\n",
      "How many resort recommendations do you want? 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>summit</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ikon</th>\n",
       "      <th>epic</th>\n",
       "      <th>mountain_collective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Snowbasin</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>9350</td>\n",
       "      <td>2900</td>\n",
       "      <td>6450</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.786659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Big Powderhorn Mountain</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Bessemer</td>\n",
       "      <td>1800</td>\n",
       "      <td>600</td>\n",
       "      <td>1200</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.784367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Plattekill Mountain</td>\n",
       "      <td>New York</td>\n",
       "      <td>Roxbury</td>\n",
       "      <td>3500</td>\n",
       "      <td>1100</td>\n",
       "      <td>2400</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.717126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ski_resort     state        city  summit  drop  base  \\\n",
       "20                 Snowbasin      Utah  Huntsville    9350  2900  6450   \n",
       "191  Big Powderhorn Mountain  Michigan    Bessemer    1800   600  1200   \n",
       "161      Plattekill Mountain  New York     Roxbury    3500  1100  2400   \n",
       "\n",
       "     intermediate_runs  advanced_runs  expert_runs  predicted_rating  ikon  \\\n",
       "20                  33             52          6.0          4.786659     1   \n",
       "191                 40             31          2.0          4.784367     0   \n",
       "161                 40              0         20.0          4.717126     0   \n",
       "\n",
       "     epic  mountain_collective  \n",
       "20      0                    1  \n",
       "191     0                    0  \n",
       "161     0                    0  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shred_recommender()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User #2 - Alexandria K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second user rated Vail and Park City Mountain low, due to the business of the resorts and overall feel of the mountain. They preferred mountains with a majority of advanced and expert terrain.\n",
    "\n",
    "2/3 of the collorative models suggestions seemed to be aligned with other resort in terms of mountain terrain and run difficulty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>summit</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stevens Pass</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Lots of snow, small local mountain.</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Skykomish</td>\n",
       "      <td>5845</td>\n",
       "      <td>1800</td>\n",
       "      <td>4061</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vail</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Lots of terrain, but very busy.</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Vail</td>\n",
       "      <td>11570</td>\n",
       "      <td>3450</td>\n",
       "      <td>8120</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snowbird</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great expert terrain, feels very grand and exc...</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Snowbird</td>\n",
       "      <td>11000</td>\n",
       "      <td>3240</td>\n",
       "      <td>7760</td>\n",
       "      <td>25</td>\n",
       "      <td>43</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Park City Mountain</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Lots of terrain, but usually very busy.  town ...</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Park City Mountain</td>\n",
       "      <td>10026</td>\n",
       "      <td>3226</td>\n",
       "      <td>6800</td>\n",
       "      <td>41</td>\n",
       "      <td>28</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ski_resort  rating  \\\n",
       "0        Stevens Pass     5.0   \n",
       "1                Vail     3.0   \n",
       "2            Snowbird     4.0   \n",
       "3  Park City Mountain     2.0   \n",
       "\n",
       "                                              review       state  \\\n",
       "0               Lots of snow, small local mountain.   Washington   \n",
       "1                   Lots of terrain, but very busy.     Colorado   \n",
       "2  Great expert terrain, feels very grand and exc...        Utah   \n",
       "3  Lots of terrain, but usually very busy.  town ...        Utah   \n",
       "\n",
       "                 city  summit  drop  base  intermediate_runs  advanced_runs  \\\n",
       "0           Skykomish    5845  1800  4061                 43             31   \n",
       "1                Vail   11570  3450  8120                 35             40   \n",
       "2            Snowbird   11000  3240  7760                 25             43   \n",
       "3  Park City Mountain   10026  3226  6800                 41             28   \n",
       "\n",
       "   expert_runs  \n",
       "0         18.0  \n",
       "1          2.0  \n",
       "2         24.0  \n",
       "3         23.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_comp(\"Alexandria K.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alexandria K.\n",
      "How many resort recommendations do you want? 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>summit</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ikon</th>\n",
       "      <th>epic</th>\n",
       "      <th>mountain_collective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Steamboat</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>Steamboat Springs</td>\n",
       "      <td>10568</td>\n",
       "      <td>3668</td>\n",
       "      <td>6900</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.529676</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Plattekill Mountain</td>\n",
       "      <td>New York</td>\n",
       "      <td>Roxbury</td>\n",
       "      <td>3500</td>\n",
       "      <td>1100</td>\n",
       "      <td>2400</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.526197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Lutsen Mountains</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Lutsen Mountains</td>\n",
       "      <td>1688</td>\n",
       "      <td>825</td>\n",
       "      <td>800</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.489648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ski_resort      state               city  summit  drop  base  \\\n",
       "42             Steamboat   Colorado  Steamboat Springs   10568  3668  6900   \n",
       "162  Plattekill Mountain   New York            Roxbury    3500  1100  2400   \n",
       "94      Lutsen Mountains  Minnesota   Lutsen Mountains    1688   825   800   \n",
       "\n",
       "     intermediate_runs  advanced_runs  expert_runs  predicted_rating  ikon  \\\n",
       "42                  43             40          5.0          4.529676     1   \n",
       "162                 40              0         20.0          4.526197     0   \n",
       "94                  58             24          8.0          4.489648     0   \n",
       "\n",
       "     epic  mountain_collective  \n",
       "42      0                    0  \n",
       "162     0                    0  \n",
       "94      0                    0  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shred_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stevens Pass', 'Vail', 'Snowbird', 'Park City Mountain']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(user_df.loc['Alexandria Kelly', 'ski_resort'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function #2  - User, Recommendation #, and State Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I added an additional filter that allows users to sort resorts by state. I will plan to further adjust the filters in the hybird and streamlit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shred_recommender_state():\n",
    "    user = str(input('Name: '))\n",
    "    n_recs = int(input('How many resort recommendations do you want? '))\n",
    "    state = str(input('What state would you like to shred in? '))\n",
    "    \n",
    "    have_rated = list(user_df.loc[user, 'ski_resort'])\n",
    "    not_rated = content_df.copy()\n",
    "    not_rated = not_rated.loc[~not_rated['ski_resort'].isin(have_rated) & (not_rated['state'] == state)]\n",
    "    not_rated = not_rated.drop_duplicates(subset=['ski_resort'])\n",
    "    not_rated.reset_index(inplace=True)\n",
    "    not_rated['predicted_rating'] = not_rated['ski_resort'].apply(lambda x: algo.predict(user, x).est)\n",
    "    not_rated.sort_values(by='predicted_rating', ascending=False, inplace=True)\n",
    "    not_rated = not_rated[['ski_resort', 'state', 'city', 'sumt', 'drop', 'base', 'intermediate_runs',\n",
    "                          'advanced_runs', 'expert_runs', 'predicted_rating', 'ikon', 'epic',\n",
    "                          'mountain_collective']].copy()\n",
    "    return not_rated.head(n_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Stephanie Ciaccia\n",
      "How many resort recommendations do you want? 3\n",
      "What state would you like to shred in? Utah\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ski_resort</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>sumt</th>\n",
       "      <th>drop</th>\n",
       "      <th>base</th>\n",
       "      <th>intermediate_runs</th>\n",
       "      <th>advanced_runs</th>\n",
       "      <th>expert_runs</th>\n",
       "      <th>predicted_rating</th>\n",
       "      <th>ikon</th>\n",
       "      <th>epic</th>\n",
       "      <th>mountain_collective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alta</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Alta</td>\n",
       "      <td>11068</td>\n",
       "      <td>2538</td>\n",
       "      <td>8530</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.457562</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Snowbasin</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>9350</td>\n",
       "      <td>2900</td>\n",
       "      <td>6450</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>4.407571</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deer Valley</td>\n",
       "      <td>Utah</td>\n",
       "      <td>Park City</td>\n",
       "      <td>9570</td>\n",
       "      <td>3000</td>\n",
       "      <td>6570</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>3.962196</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ski_resort state        city   sumt  drop  base  intermediate_runs  \\\n",
       "0         Alta  Utah        Alta  11068  2538  8530                  0   \n",
       "8    Snowbasin  Utah  Huntsville   9350  2900  6450                 33   \n",
       "4  Deer Valley  Utah   Park City   9570  3000  6570                 31   \n",
       "\n",
       "   advanced_runs  expert_runs  predicted_rating  ikon  epic  \\\n",
       "0              0            0          4.457562     1     0   \n",
       "8             52            6          4.407571     1     0   \n",
       "4             10           32          3.962196     1     0   \n",
       "\n",
       "   mountain_collective  \n",
       "0                    1  \n",
       "8                    1  \n",
       "4                    0  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shred_recommender_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the outputs and RMSE score indicates that the recommendation system effectively suggests ski resorts that are generally aligned with user ratings. However, considering the high opportunity cost associated with planning a ski trip, relying solely on a user-based system is insufficient to provide users with tailored recommendations that account for factors such as cost and time of year. While identifying similar users is crucial, it is essential to consider additional elements when making recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps involves implementing a content-based system and integrating the results with the collaborative model. This combined approach enhances the filtering capabilities of the collaborative model, allowing for more dynamic filtering based on user preferences. By incorporating both content-based and collaborative filtering, the system will deliver more accurate recommendations that align closely with user preferences, resulting in a more refined and personalized recommendation system.\n",
    "\n",
    "The **Cascade Hybrid Modeling** notebook will be saved in the main github repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
